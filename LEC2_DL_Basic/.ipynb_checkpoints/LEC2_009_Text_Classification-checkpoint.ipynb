{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa61081b-8b84-4d24-9cf5-f189c5c86baf",
   "metadata": {},
   "source": [
    "### Created on 2025\n",
    "### @author: S.W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0358ebe7-8628-4f93-af3b-b9d0b87ce441",
   "metadata": {},
   "source": [
    "### 0. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52da7d53-665b-4519-8f31-3e6d9e9f118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, random, numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments, \n",
    "    Trainer, \n",
    "    pipeline\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED); random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b58166-df2a-4378-9d72-1424c540c902",
   "metadata": {},
   "source": [
    "#### 1. ë°ì´í„° ë¡œë“œ  (IMDb ë¦¬ë·°: label 0=ë¶€ì •, 1=ê¸ì •)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "483e8d69-4729-4837-903c-1990538e85a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ë°ì´í„°ì…‹ ê¸°ë³¸ ì •ë³´:\n",
      "  ì „ì²´ êµ¬ì¡°: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 25000\n",
      "    })\n",
      "    unsupervised: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 50000\n",
      "    })\n",
      "})\n",
      "  í›ˆë ¨ ì„¸íŠ¸ í¬ê¸°: 25,000ê°œ\n",
      "  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í¬ê¸°: 25,000ê°œ\n"
     ]
    }
   ],
   "source": [
    "raw_ds = load_dataset(\"imdb\")                 # train / test ë¶„ë¦¬ë¼ ì œê³µ\n",
    "\n",
    "# ë°ì´í„°ì…‹ êµ¬ì¡° í™•ì¸\n",
    "print(f\"  ë°ì´í„°ì…‹ ê¸°ë³¸ ì •ë³´:\")\n",
    "print(f\"  ì „ì²´ êµ¬ì¡°: {raw_ds}\")\n",
    "print(f\"  í›ˆë ¨ ì„¸íŠ¸ í¬ê¸°: {len(raw_ds['train']):,}ê°œ\")\n",
    "print(f\"  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í¬ê¸°: {len(raw_ds['test']):,}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21fe1d1d-ebb2-4f6d-bbd1-0c1d28a71f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = raw_ds[\"train\"].shuffle(SEED).select(range(8000))   # ë°ëª¨ìš© ì†Œê·œëª¨ ìƒ˜í”Œ\n",
    "test_ds  = raw_ds[\"test\"].shuffle(SEED).select(range(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edbe6fe5-dfb6-4a73-a8c6-a69cbd63ec2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” ì²« ë²ˆì§¸ ìƒ˜í”Œ í™•ì¸:\n",
      "  ë¦¬ë·° ë‚´ìš© (ì²˜ìŒ 200ì): 'There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. F...'\n",
      "  ê°ì • ë ˆì´ë¸”: 1 (ê¸ì •)\n",
      "\n",
      "ğŸ“ˆ í›ˆë ¨ ë°ì´í„° ë ˆì´ë¸” ë¶„í¬ í™•ì¸:\n",
      "  ê¸ì • ë¦¬ë·° (label=1): 12,500ê°œ (50.0%)\n",
      "  ë¶€ì • ë¦¬ë·° (label=0): 12,500ê°œ (50.0%)\n",
      "  â†’ ê· í˜•ì¡íŒ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ìƒ˜í”Œ í™•ì¸\n",
    "print(f\"\\nğŸ” ì²« ë²ˆì§¸ ìƒ˜í”Œ í™•ì¸:\")\n",
    "first_sample = train_ds[0]\n",
    "print(f\"  ë¦¬ë·° ë‚´ìš© (ì²˜ìŒ 200ì): '{first_sample['text'][:200]}...'\")\n",
    "print(f\"  ê°ì • ë ˆì´ë¸”: {first_sample['label']} ({'ê¸ì •' if first_sample['label'] == 1 else 'ë¶€ì •'})\")\n",
    "\n",
    "# ë ˆì´ë¸” ë¶„í¬ í™•ì¸\n",
    "print(f\"\\nğŸ“ˆ í›ˆë ¨ ë°ì´í„° ë ˆì´ë¸” ë¶„í¬ í™•ì¸:\")\n",
    "train_labels = [sample['label'] for sample in raw_ds[\"train\"]]\n",
    "positive_count = sum(train_labels)\n",
    "negative_count = len(train_labels) - positive_count\n",
    "\n",
    "print(f\"  ê¸ì • ë¦¬ë·° (label=1): {positive_count:,}ê°œ ({positive_count/len(train_labels)*100:.1f}%)\")\n",
    "print(f\"  ë¶€ì • ë¦¬ë·° (label=0): {negative_count:,}ê°œ ({negative_count/len(train_labels)*100:.1f}%)\")\n",
    "print(f\"  â†’ ê· í˜•ì¡íŒ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c77e915-b246-428b-9710-42b7d007914b",
   "metadata": {},
   "source": [
    "#### 2. í† í¬ë‚˜ì´ì € ë° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65265247-3bd4-4302-ab84-acda4f63d068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# BERT ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ ì´ë¦„ ì„¤ì •\n",
    "# \"bert-base-uncased\": ì†Œë¬¸ìë¡œ ë³€í™˜ëœ ê¸°ë³¸ BERT ëª¨ë¸\n",
    "# - base: 12ê°œ ë ˆì´ì–´, 768ì°¨ì› íˆë“  ì‚¬ì´ì¦ˆ (small ë²„ì „ë„ ìˆìŒ)\n",
    "# - uncased: ëŒ€ì†Œë¬¸ìë¥¼ êµ¬ë¶„í•˜ì§€ ì•ŠìŒ (ëª¨ë“  í…ìŠ¤íŠ¸ê°€ ì†Œë¬¸ìë¡œ ë³€í™˜ë¨)\n",
    "model_ckpt = \"bert-base-uncased\"\n",
    "\n",
    "# ì‚¬ì „ í›ˆë ¨ëœ BERT í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "# í† í¬ë‚˜ì´ì €: í…ìŠ¤íŠ¸ë¥¼ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ«ì(í† í° ID)ë¡œ ë³€í™˜í•˜ëŠ” ë„êµ¬\n",
    "# BERTëŠ” WordPiece í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš© (ë‹¨ì–´ë¥¼ ì„œë¸Œì›Œë“œë¡œ ë¶„í• )\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "\n",
    "def tokenize(batch):\n",
    "    \"\"\"\n",
    "    ë°°ì¹˜ ë‹¨ìœ„ë¡œ í…ìŠ¤íŠ¸ë¥¼ í† í¬ë‚˜ì´ì¦ˆí•˜ëŠ” í•¨ìˆ˜\n",
    "    \n",
    "    Args:\n",
    "        batch (dict): 'text' í‚¤ë¥¼ ê°€ì§„ ë°°ì¹˜ ë°ì´í„°\n",
    "        \n",
    "    Returns:\n",
    "        dict: í† í¬ë‚˜ì´ì¦ˆëœ ê²°ê³¼ (input_ids, attention_mask ë“±)\n",
    "    \"\"\"\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],           # í† í¬ë‚˜ì´ì¦ˆí•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸\n",
    "        truncation=True         # ìµœëŒ€ ê¸¸ì´ë¥¼ ì´ˆê³¼í•˜ë©´ ìë™ìœ¼ë¡œ ì˜ë¼ë‚´ê¸°\n",
    "                               # BERTì˜ ê¸°ë³¸ ìµœëŒ€ ê¸¸ì´ëŠ” 512 í† í°\n",
    "    )\n",
    "\n",
    "# í›ˆë ¨ ë°ì´í„°ì…‹ì— í† í¬ë‚˜ì´ì œì´ì…˜ ì ìš©\n",
    "# map í•¨ìˆ˜: ë°ì´í„°ì…‹ì˜ ëª¨ë“  ìƒ˜í”Œì— ëŒ€í•´ tokenize í•¨ìˆ˜ ì ìš©\n",
    "train_ds = train_ds.map(\n",
    "    tokenize,                   # ì ìš©í•  í•¨ìˆ˜\n",
    "    batched=True,              # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬ (ì†ë„ í–¥ìƒ)\n",
    "    remove_columns=[\"text\"]    # ì›ë³¸ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ ì œê±° (ë©”ëª¨ë¦¬ ì ˆì•½)\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì—ë„ ë™ì¼í•˜ê²Œ ì ìš©\n",
    "test_ds = test_ds.map(\n",
    "    tokenize, \n",
    "    batched=True, \n",
    "    remove_columns=[\"text\"]\n",
    ")\n",
    "\n",
    "# ë°ì´í„° ì½œë ˆì´í„° ì„¤ì •\n",
    "# DataCollatorWithPadding: ë°°ì¹˜ ë‚´ì—ì„œ ê¸¸ì´ê°€ ë‹¤ë¥¸ ì‹œí€€ìŠ¤ë“¤ì„ ë™ì¼í•œ ê¸¸ì´ë¡œ ë§ì¶¤\n",
    "# - ì§§ì€ ì‹œí€€ìŠ¤ì—ëŠ” íŒ¨ë”© í† í°([PAD])ì„ ì¶”ê°€\n",
    "# - attention_maskë„ ìë™ìœ¼ë¡œ ìƒì„± (ì‹¤ì œ í† í°ì€ 1, íŒ¨ë”©ì€ 0)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bf5e8b-74ef-48fb-96d2-b887b90d3669",
   "metadata": {},
   "source": [
    "#### 3. ëª¨ë¸ ì´ˆê¸°í™” (ì¶œë ¥ ë¼ë²¨ 2ê°œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78177da7-07f2-4d33-a9aa-dfedf61c90a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# ì‚¬ì „ í›ˆë ¨ëœ BERT ëª¨ë¸ì„ ë¶„ë¥˜ ì‘ì—…ìš©ìœ¼ë¡œ ë¡œë“œ\n",
    "# AutoModelForSequenceClassification: ì‹œí€€ìŠ¤ ë¶„ë¥˜ë¥¼ ìœ„í•œ ëª¨ë¸ í´ë˜ìŠ¤\n",
    "# - ê¸°ì¡´ BERT ëª¨ë¸ ìœ„ì— ë¶„ë¥˜ìš© í—¤ë“œ(classifier head)ê°€ ì¶”ê°€ë¨\n",
    "# - ë¶„ë¥˜ í—¤ë“œ: 768ì°¨ì› â†’ num_labelsì°¨ì›ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì„ í˜• ë ˆì´ì–´\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_ckpt,          # ì‚¬ìš©í•  ì‚¬ì „ í›ˆë ¨ ëª¨ë¸ (\"bert-base-uncased\")\n",
    "    num_labels=2         # ì¶œë ¥ ë¼ë²¨ì˜ ê°œìˆ˜ (ì´ì§„ ë¶„ë¥˜ì´ë¯€ë¡œ 2ê°œ)\n",
    "                        # ì˜ˆ: ê¸ì •(1), ë¶€ì •(0) ë˜ëŠ” ìŠ¤íŒ¸(1), ì •ìƒ(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdbebf0-70e0-42f3-905a-c1f75bf5d641",
   "metadata": {},
   "source": [
    "#### 4. í‰ê°€ì§€í‘œ í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da683bef-518c-45fd-9931-6751f019b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” í•¨ìˆ˜\n",
    "    Trainerì—ì„œ validation ì¤‘ì— ìë™ìœ¼ë¡œ í˜¸ì¶œë¨\n",
    "    \n",
    "    Args:\n",
    "        eval_pred (EvalPrediction): ì˜ˆì¸¡ ê²°ê³¼ì™€ ì •ë‹µ ë¼ë²¨ì„ ë‹´ì€ ê°ì²´\n",
    "            - predictions: ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ (ë¡œì§“/ì ìˆ˜)\n",
    "            - label_ids: ì‹¤ì œ ì •ë‹µ ë¼ë²¨\n",
    "    \n",
    "    Returns:\n",
    "        dict: í‰ê°€ ì§€í‘œë“¤ì˜ ë”•ì…”ë„ˆë¦¬\n",
    "    \"\"\"\n",
    "    \n",
    "    # eval_predì—ì„œ ì˜ˆì¸¡ê°’(ë¡œì§“)ê³¼ ì •ë‹µ ë¼ë²¨ ì¶”ì¶œ\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    # ë¡œì§“ì„ ì‹¤ì œ ì˜ˆì¸¡ í´ë˜ìŠ¤ë¡œ ë³€í™˜\n",
    "    # argmax: ê°€ì¥ í° ê°’ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜\n",
    "    # axis=-1: ë§ˆì§€ë§‰ ì°¨ì›(í´ë˜ìŠ¤ ì°¨ì›)ì—ì„œ ìµœëŒ€ê°’ ì°¾ê¸°\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    \n",
    "    # í‰ê°€ ì§€í‘œ ê³„ì‚° ë° ë°˜í™˜\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e17c328-ecf4-4bb3-963f-1854f4878e0b",
   "metadata": {},
   "source": [
    "#### 5. í•™ìŠµ ì„¸íŒ… ë° Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfd57bc6-c40e-43ff-a88f-ae561bc398a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 04:10, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.212452</td>\n",
       "      <td>0.921000</td>\n",
       "      <td>0.922167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.9210,  F1: 0.9222\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert-imdb\",\n",
    "    num_train_epochs=1,              # ë°ëª¨ìš© 1 epoch\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    fp16=torch.cuda.is_available(),  # GPU-FP16 ê°€ì†\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "metrics = trainer.evaluate()\n",
    "print(f\"\\nTest accuracy: {metrics['eval_accuracy']:.4f},  F1: {metrics['eval_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff1bb59-277b-4a75-922c-76a2214a7fde",
   "metadata": {},
   "source": [
    "#### 6. ì¶”ë¡ (Inference) íŒŒì´í”„ë¼ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b68508d6-904e-4b84-a5d9-faed105bc7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/crocus/.cache/torch_extensions/py39_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/crocus/.cache/torch_extensions/py39_cu118/cuda_kernel/build.ninja...\n",
      "Building extension module cuda_kernel...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/4] /usr/local/cuda-11.8/bin/nvcc  -DTORCH_EXTENSION_NAME=cuda_kernel -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/torch/include -isystem /home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/torch/include/TH -isystem /home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/torch/include/THC -isystem /usr/local/cuda-11.8/include -isystem /home/crocus/anaconda3/envs/keri_test/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -std=c++17 -c /home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/transformers/kernels/mra/cuda_kernel.cu -o cuda_kernel.cuda.o \n",
      "[2/4] c++ -MMD -MF torch_extension.o.d -DTORCH_EXTENSION_NAME=cuda_kernel -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/torch/include -isystem /home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/torch/include/TH -isystem /home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/torch/include/THC -isystem /usr/local/cuda-11.8/include -isystem /home/crocus/anaconda3/envs/keri_test/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/transformers/kernels/mra/torch_extension.cpp -o torch_extension.o \n",
      "[3/4] /usr/local/cuda-11.8/bin/nvcc  -DTORCH_EXTENSION_NAME=cuda_kernel -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/torch/include -isystem /home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/torch/include/torch/csrc/api/include -isystem /home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/torch/include/TH -isystem /home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/torch/include/THC -isystem /usr/local/cuda-11.8/include -isystem /home/crocus/anaconda3/envs/keri_test/include/python3.9 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_75,code=sm_75 -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -std=c++17 -c /home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/transformers/kernels/mra/cuda_launch.cu -o cuda_launch.cuda.o \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module cuda_kernel...\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/4] c++ cuda_kernel.cuda.o cuda_launch.cuda.o torch_extension.o -shared -L/home/crocus/anaconda3/envs/keri_test/lib/python3.9/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda-11.8/lib64 -lcudart -o cuda_kernel.so\n",
      "\n",
      "=== Prediction Examples ===\n",
      "This movie was an absolute masterpiece. Brilliant acting!  ->  {'label': 'LABEL_1', 'score': 0.9814226627349854}\n",
      "I wish I could get my two hours back. It was painfully boring.  ->  {'label': 'LABEL_0', 'score': 0.9322379231452942}\n"
     ]
    }
   ],
   "source": [
    "clf = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "samples = [\n",
    "    \"This movie was an absolute masterpiece. Brilliant acting!\",\n",
    "    \"I wish I could get my two hours back. It was painfully boring.\"\n",
    "]\n",
    "\n",
    "print(\"\\n=== Prediction Examples ===\")\n",
    "for s in samples:\n",
    "    print(f\"{s}  ->  {clf(s)[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI Course (Python 3.9)",
   "language": "python",
   "name": "ai_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
