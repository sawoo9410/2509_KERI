{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f864d08d",
   "metadata": {},
   "source": [
    "### Created on 2025\n",
    "### @author: S.W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fd3df5-906d-42e7-adfe-3dcfb31f4f8f",
   "metadata": {},
   "source": [
    "PyTorch는 파이썬 기반의 오픈소스 머신러닝 프레임워크로, 텐서 연산 및 그래프 생성, 자동 미분 등을 지원하여 딥러닝 모델의 학습 및 추론을 쉽게 구현할 수 있습니다.<br>\n",
    "PyTorch 공식 홈페이지에서 제공하는 튜토리얼 중 하나인 \"예제로 배우는 PyTorch\"를 기반으로 PyTorch의 기초적인 개념과 사용 방법을 설명하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217e9211-e5d5-4bf3-a42b-3a58af74b07a",
   "metadata": {},
   "source": [
    "## 1. 데이터셋 다운로드와 기본 전처리 실습\n",
    "PyTorch는 머신러닝 데이터셋을 쉽게 불러오고 전처리할 수 있도록 torchvision이라는 부가 패키지를 제공합니다.<br>\n",
    "MNIST라는 손글씨 숫자 이미지 데이터셋을 사용해 실습을 진행합니다.<br>\n",
    "MNIST 데이터는 0부터 9까지의 손글씨 숫자(이미지로 28x28 크기, 흑백)로 구성되어 있어 딥러닝 입문에 자주 사용됩니다.<br>\n",
    "<br>\n",
    "실습 목표<br>\n",
    "- MNIST 데이터셋을 다운로드해 학습용과 테스트용으로 분리하기\n",
    "- 이미지를 PyTorch 텐서로 변환 및 정규화(Normalize) 처리하기\n",
    "- 데이터를 한 번에 여러 장씩 불러오기 위한 DataLoader 사용법 익히기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef0b45be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 6201808.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 168411.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1537115.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 1613084.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. PyTorch와 torchvision 패키지 임포트\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 2. 이미지 데이터에 적용할 전처리(transform) 정의\n",
    "# - ToTensor(): 이미지를 PyTorch 텐서로 변환 (0~255 → 0~1로 정규화)\n",
    "# - Normalize(): 각 픽셀을 평균 0.5, 표준편차 0.5로 정규화\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 3. 학습용(train) MNIST 데이터셋 다운로드 및 전처리 적용\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root='./data',            # 데이터 저장 경로\n",
    "    train=True,               # 학습용 데이터 선택\n",
    "    download=True,            # 데이터가 없으면 다운로드\n",
    "    transform=transform       # 앞서 정의한 전처리 적용\n",
    ")\n",
    "\n",
    "# 4. 학습 데이터를 미니배치 단위로 묶기. (배치 크기=4장, 셔플=적용)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=4,             # 한 번에 불러올 데이터 개수\n",
    "    shuffle=True,             # 매 epoch마다 데이터 섞기\n",
    "    num_workers=2             # 데이터를 불러올 때 사용할 CPU 코어 수\n",
    ")\n",
    "\n",
    "# 5. 테스트(test) 데이터셋도 동일하게 불러오기\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,              # 테스트용 데이터 선택\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,            # 테스트 데이터는 셔플 없이 순서대로\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccc210d",
   "metadata": {},
   "source": [
    "### 데이터 전처리 및 데이터셋 준비 과정 설명\n",
    "PyTorch에서 딥러닝을 위한 데이터 준비는 효율성과 일관성이 매우 중요합니다.<br>\n",
    "아래 내용은 위 코드에서 사용된 주요 전처리, 데이터셋 로딩, DataLoader 구성법에 대한 설명입니다.<br>\n",
    "\n",
    "#### 1. 전처리(Preprocessing) 조합\n",
    "torchvision.transforms.Compose를 사용하면 여러 전처리(transform) 기능을 순서대로 묶어 한 번에 적용할 수 있습니다.<br>\n",
    "첫 단계로 ToTensor() 함수가 이미지를 PyTorch 텐서로 변환합니다.<br>\n",
    "일반적으로 입력 이미지는 0-255 범위의 픽셀값을 가지지만, ToTensor()를 거치면 0.0-1.0 범위의 실수 값으로 변환됩니다.<br>\n",
    "<br>\n",
    "이어서 Normalize((0.5,), (0.5,))를 적용하면, 모든 픽셀 값이 -1.0~1.0 범위로 재조정(정규화)됩니다.<br>\n",
    "<br>\n",
    "수식: 정규화된 값 =  (원본 값 − 0.5)/0.5 <br>\n",
    "\n",
    "adv. 원래 인공신경망은 입력 데이터를 전처리시 0과 1 사이로 정규화하는 것이 기본적입니다. <br>\n",
    "그러나, -1과 1사이로 정규화하는 경우는 활성화 함수가 tanh 함수 같이 -1~1에 최적화된 함수이거나, 데이터 분포의 중심을 0으로 하는 것이 종종 더 안정적인 학습을 지원할 수 있기 때문입니다.<br>\n",
    "\n",
    "\n",
    "#### 2. MNIST 데이터셋 불러오기\n",
    "torchvision.datasets.MNIST 클래스를 이용하여 손쉽게 MNIST 숫자 이미지 데이터셋을 다운로드합니다.<br>\n",
    "train=True: 학습용 데이터셋(6만 장)을 불러옵니다.<br>\n",
    "train=False: 테스트용 데이터셋(1만 장)을 불러옵니다.<br>\n",
    "두 경우 모두, 앞서 정의한 전처리(Compose로 조합된 ToTensor와 Normalize)를 동일하게 적용하므로, 학습·평가 시 입력 데이터 분포의 일관성을 보장합니다.<br>\n",
    "\n",
    "#### 3. DataLoader로 배치 처리\n",
    "PyTorch에 내장된 torch.utils.data.DataLoader는 대용량 데이터를 효율적으로 다루기 위해 작은 배치(batch) 단위로 데이터를 나누어 불러오는 역할을 합니다.<br>\n",
    "학습 데이터는 shuffle=True 옵션을 통해 각 epoch마다 데이터를 섞어줍니다(모델의 일반화 성능 향상에 도움).<br>\n",
    "테스트 데이터는 shuffle=False로 순서대로 불러옵니다.<br>\n",
    "batch_size=4는 한 번에 4개의 이미지를 로드하여 네트워크에 전달한다는 의미입니다. 이 값은 실험 목적, 시스템 자원, 네트워크 구조 등에 따라 변경할 수 있습니다.<br>\n",
    "\n",
    "#### 전체 흐름 다시 보기\n",
    "1. 전처리(transform) 정의: 이미지를 텐서로 변환 → 정규화 수행<br>\n",
    "2. 데이터셋(loader) 준비: 각 데이터셋(MNIST)을 학습(train)/평가(test) 모드로 별도 불러옴<br>\n",
    "3. DataLoader로 미니배치 구성: 효율적 학습 및 메모리 사용<br>\n",
    "\n",
    "이렇게 준비된 데이터셋과 DataLoader는 이후 딥러닝 모델 구현 및 학습에 바로 활용할 수 있습니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef697352",
   "metadata": {},
   "source": [
    "## 2. 신경망 모델 정의\n",
    "PyTorch에서는 딥러닝 모델을 직접 설계할 수 있도록 nn.Module 클래스를 상속하여 신경망을 정의합니다.<br>\n",
    "신경망을 직접 정의하고, 각 계층(layer)과 활성화 함수(activation function)를 어떻게 연결하는지 이해하는 것은 딥러닝 구현에서 매우 중요한 과정입니다.<br>\n",
    "<br>\n",
    "(1) 신경망(Neural Network) 설계 방법\n",
    "- 클래스(class) 상속 구조: 새로운 네트워크 구조는 nn.Module 클래스를 상속받아 만듭니다.\n",
    "- 생성자 함수(__ init __): 네트워크의 각 계층(fully-connected, convolution 등)은 생성자에서 미리 선언합니다.\n",
    "- 순전파 함수(forward): 입력 데이터를 받아 층을 통과시켜 예측값을 반환하는 논리를 정의합니다.\n",
    "\n",
    "\n",
    "아래는 입력(28x28 이미지를 펼친 784차원 벡터)을 500차원 은닉층(hidden layer)과 10차원 출력(분류 클래스)으로 변환하는 단순 다층 퍼셉트론(Multilayer Perceptron) 모델 예시입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bc07650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 입력층: 784(28x28 픽셀) → 500\n",
    "        self.fc1 = nn.Linear(784, 500)\n",
    "        # 활성화 함수 (ReLU) 선언\n",
    "        self.relu = nn.ReLU()\n",
    "        # 출력층: 500 → 10 (0~9 숫자 분류)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 입력을 1차원 벡터로 가정 (이미지 펼치기 등 사전 필요)\n",
    "        out = self.fc1(x)    # 첫 번째 선형 변환(가중치 연산)\n",
    "        out = self.relu(out) # 비선형 활성화 적용\n",
    "        out = self.fc2(out)  # 두 번째 선형 변환\n",
    "        return out           # 최종 출력값 반환\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c86b01-c199-4752-b63c-790e0d8e4b95",
   "metadata": {},
   "source": [
    "nn.Linear(input_dim, output_dim): 완전 연결(fully connected) 계층을 나타냅니다.<br>\n",
    "nn.ReLU(): 은닉층에 비선형성을 부여하는 대표적인 활성화 함수입니다.<br>\n",
    "forward 메서드: 실제 입력이 모델을 통과할 때 계층을 순서대로 연결하는 논리입니다.<br>\n",
    "클래스 정의 후 net = Net()으로 모델 객체를 생성하고, print(net)으로 구조를 확인할 수 있습니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfc2af3",
   "metadata": {},
   "source": [
    "## 3. 데이터 로드 및 학습\n",
    "\n",
    "이 단계에서는 준비된 데이터셋과 정의한 신경망 모델을 조합하여 모델을 실제로 학습시키는 과정을 다룹니다.<br>\n",
    "딥러닝 모델 학습의 전체적인 흐름(전처리 → 신경망 정의 → 학습)을 직접 경험할 수 있는 핵심 단계입니다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "418ba681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.626\n",
      "[1,  4000] loss: 0.360\n",
      "[1,  6000] loss: 0.310\n",
      "[1,  8000] loss: 0.259\n",
      "[1, 10000] loss: 0.225\n",
      "[1, 12000] loss: 0.201\n",
      "[1, 14000] loss: 0.180\n",
      "[2,  2000] loss: 0.161\n",
      "[2,  4000] loss: 0.152\n",
      "[2,  6000] loss: 0.146\n",
      "[2,  8000] loss: 0.133\n",
      "[2, 10000] loss: 0.125\n",
      "[2, 12000] loss: 0.129\n",
      "[2, 14000] loss: 0.125\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# 신경망 학습\n",
    "import torch.optim as optim\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()  # 다중 분류 손실 함수\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)  # SGD 옵티마이저\n",
    "\n",
    "# 네트워크 학습 시작\n",
    "for epoch in range(2):  # 데이터셋 전체를 2번 반복(2 epochs)\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 1. 데이터 분할 (입력과 레이블)\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.reshape(-1, 28*28)  # 2차원 이미지를 펼쳐 1차원 벡터로 변환\n",
    "\n",
    "        # 2. 순전파(forward)\n",
    "        outputs = net(inputs)                  # 입력을 신경망에 전달하여 예측값 생성\n",
    "        loss = criterion(outputs, labels)      # 예측값과 정답으로 손실(오차) 계산\n",
    "        \n",
    "        # 3. 역전파(backward) 및 최적화\n",
    "        optimizer.zero_grad()    # 이전 배치의 기울기(gradient)를 초기화\n",
    "        loss.backward()          # 오차로부터 모든 파라미터의 기울기 계산(역전파)\n",
    "        optimizer.step()         # 계산된 기울기로 파라미터 갱신(최적화)\n",
    "\n",
    "        # 4. 손실 누적 및 주기별 로깅\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:  # 2000번째 배치마다 평균 손실 출력\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c49b2a",
   "metadata": {},
   "source": [
    "### 신경망 학습 단계 요약\n",
    "#### (1) 손실 함수와 최적화 함수 설정\n",
    "\n",
    "손실 함수 (nn.CrossEntropyLoss())\n",
    "- 분류 문제에 최적화된 교차 엔트로피 손실 함수를 사용합니다.\n",
    "- 네트워크의 예측값과 실제 정답(레이블) 사이의 오차를 수치로 측정하여, 해당 값을 최소화하는 방향으로 학습이 이루어집니다.\n",
    "\n",
    "최적화 함수 (optim.SGD()):\n",
    "- 확률적 경사 하강법(Stochastic Gradient Descent, SGD) 알고리즘을 사용합니다.\n",
    "- lr 파라미터는 학습률을, momentum 파라미터는 모멘텀 값을 지정해 학습의 효율성과 안정성을 향상시킵니다.\n",
    "\n",
    "#### (2) 학습 루프 동작 흐름\n",
    "- trainloader에서 배치를 하나씩 가져옵니다. 각 배치는 inputs(입력 데이터)와 labels(정답 레이블)로 분리됩니다.\n",
    "\n",
    "학습 반복의 주요 처리는 아래와 같습니다:\n",
    "- 기울기 초기화: optimizer.zero_grad()로 매 반복마다 누적된 변화도를 초기화합니다.\n",
    "- 순전파(Forward): net(inputs)을 통해 입력값이 신경망을 통과하여 예측 결과(outputs)를 계산합니다.\n",
    "- 손실 계산: criterion(outputs, labels)로 예측 결과와 정답 간의 손실값(loss)을 산출합니다.\n",
    "- 역전파(Backward): loss.backward()를 호출하여 손실에 대한 가중치의 기울기를 계산합니다.\n",
    "- 최적화 및 갱신: optimizer.step()으로 계산된 기울기를 바탕으로 신경망 파라미터를 업데이트합니다.\n",
    "\n",
    "#### (3) 손실(오차) 모니터링 및 출력\n",
    "- 각 에폭(epoch) 및 모든 반복에서 running loss를 누적 합산합니다.\n",
    "- i % 2000 == 1999 조건을 사용해 2,000번째 배치마다 평균 손실값을 출력합니다.\n",
    "- 이 과정을 통해 학습이 정상적으로 이뤄지는지, 손실이 줄어드는 추세인지 실시간으로 확인할 수 있습니다.\n",
    "\n",
    "#### (4) 학습 종료 메시지\n",
    "- 모든 에폭의 학습이 끝난 후 'Finished Training' 메시지를 출력합니다.\n",
    "- 이를 통해 모델 학습이 정상적으로 완료되었음을 쉽게 알 수 있습니다.\n",
    "\n",
    "이러한 흐름을 통해 데이터 준비, 신경망 정의, 학습, 손실 모니터링, 종료에 이르기까지 딥러닝 모델의 학습 구조를 직관적으로 파악할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46208faa",
   "metadata": {},
   "source": [
    "## 4. 테스트 데이터 예측 및 평가\n",
    "학습이 완료된 신경망 모델의 성능을 평가하기 위해, 준비된 테스트 데이터셋(MNIST 사전에 분리된 10,000장 이미지)을 활용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9554e473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.650000 %\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터셋으로 모델 성능 평가\n",
    "correct = 0   # 정답 개수 누적\n",
    "total = 0     # 전체 샘플 개수\n",
    "\n",
    "with torch.no_grad():  # 평가 중에는 기울기(gradient) 계산 비활성화\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.reshape(-1, 28*28)           # 1차원 벡터로 변환\n",
    "        outputs = net(images)                        # 신경망 예측 결과\n",
    "        _, predicted = torch.max(outputs.data, 1)    # 예측값(가장 높은 점수의 클래스 선택)\n",
    "        total += labels.size(0)                      # 전체 샘플 개수 누적\n",
    "        correct += (predicted == labels).sum().item()# 정답 맞춘 샘플 개수 누적\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0984312",
   "metadata": {},
   "source": [
    "### 테스트 데이터셋을 활용한 모델 평가 절차\n",
    "학습이 완료된 신경망 모델의 성능을 객관적으로 측정하기 위해 별도의 테스트 데이터셋을 사용합니다.<br>\n",
    "이 과정에서는 모델이 훈련 데이터에서 보지 않은 새로운 샘플에 대해 얼마나 일반화되는지 평가할 수 있습니다.<br>\n",
    "#### 평가 단계 요약\n",
    "(1) Gradient 계산 방지\n",
    "- torch.no_grad() 구문을 이용하여 추론 과정에서 변화도 계산을 비활성화합니다.\n",
    "- 이를 통해 불필요한 메모리 사용을 방지하고, 평가 속도를 높일 수 있습니다.\n",
    "\n",
    "(2) 테스트 데이터 로드\n",
    "- testloader에서 하나씩 배치를 반복적으로 가져옵니다.\n",
    "- 각 배치는 입력 이미지(images)와 정답 레이블(labels)로 구성됩니다.\n",
    "\n",
    "(3) 예측값 계산 및 라벨 추출\n",
    "- 불러온 이미지를 신경망(net)에 입력해 예측값(outputs)을 얻습니다.\n",
    "- torch.max() 함수를 통해 예측 결과에서 각 샘플마다 가장 큰 값을 갖는 클래스의 인덱스를 선택하여, 예측된 라벨(predicted)로 사용합니다.\n",
    "\n",
    "(4) 정확하게 예측한 샘플 집계\n",
    "- 예측된 라벨(predicted)과 실제 정답 레이블(labels)을 비교하여, 일치하는 경우의 수를 correct에 누적합니다.\n",
    "- 전체 테스트 샘플 수를 total에 누적합니다.\n",
    "\n",
    "(5) 정확도(Accuracy) 산출\n",
    "- 정확도는 전체 샘플 중 올바르게 예측한 샘플의 비율입니다\n",
    "- 최종적으로 신경망의 전체 테스트 데이터셋에 대한 성능을 정확도로 판단합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199f8973",
   "metadata": {},
   "source": [
    "## 6. 학습한 모델 저장\n",
    "신경망 모델이 충분히 학습되었다면, 추후 재사용이나 배포, 중간 저장을 위해 모델의 파라미터(가중치와 편향)를 파일로 저장할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caa47de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './mnist_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b977ba00",
   "metadata": {},
   "source": [
    "학습이 완료된 모델을 torch.save()로 저장했다면, 추후 언제든지 동일한 신경망 구조 내에서 모델 파라미터를 쉽게 복원할 수 있습니다.<br>\n",
    "이 과정을 통해 불필요하게 다시 학습하지 않고도 바로 추론 및 추가 실험을 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101b9c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 1. 테스트 데이터셋 다운로드 및 전처리\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=False,              # 테스트 데이터\n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=4, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "# 2. 신경망 클래스 정의\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 500)  # 입력층: 784 -> 500\n",
    "        self.relu = nn.ReLU()           # 활성화 함수\n",
    "        self.fc2 = nn.Linear(500, 10)   # 출력층: 500 -> 10\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "net = Net()\n",
    "print(net)  # 모델 구조 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "543b9d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = './mnist_net.pth'  # 모델 파라미터를 저장한 파일 경로 지정\n",
    "\n",
    "net = Net()  # 신경망(Net) 객체를 새로 생성 (구조는 반드시 저장 당시와 같아야 함)\n",
    "net.load_state_dict(torch.load(PATH))  # 저장된 state_dict(모델 파라미터)를 파일로부터 읽어와 네트워크에 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa20442a",
   "metadata": {},
   "source": [
    "훈련이 완료된 모델을 추후 재사용하기 위해 저장한 state_dict를 다시 로드하는 과정을 진행합니다.<br>\n",
    "<br>\n",
    "동작 흐름<br>\n",
    "1. 빈 모델 생성<br>\n",
    "Net() 클래스를 사용하여 구조만 동일한 빈 신경망 객체를 만듭니다. 이때 중요한 점은, 모델 구조가 저장 당시와 완전히 같아야 파라미터를 제대로 로드할 수 있다는 것입니다.\n",
    "\n",
    "2. 저장된 파라미터 불러오기<br>\n",
    "load_state_dict() 메서드를 이용해 .pth 파일로 저장된 모델의 파라미터(state_dict)를 불러와 모델에 적용합니다.\n",
    "\n",
    "3. 예측 수행 가능<br>\n",
    "불러온 모델은 학습이 완료된 상태와 동일한 파라미터 값을 가지므로, 해당 모델을 평가, 추론 등에 바로 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0074f4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.650000 %\n"
     ]
    }
   ],
   "source": [
    "# 신경망의 MNIST 테스트셋 분류 정확도 평가\n",
    "correct = 0   # 맞게 예측한 샘플 수\n",
    "total = 0     # 전체 샘플 수\n",
    "\n",
    "with torch.no_grad():  # 추론(평가) 단계에서는 변화도 미계산\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.reshape(-1, 28*28)           # 1차원 벡터로 변환\n",
    "        outputs = net(images)                        # 신경망의 예측값 산출\n",
    "        _, predicted = torch.max(outputs.data, 1)    # 각 샘플별 예측 라벨 선택\n",
    "        total += labels.size(0)                      # 전체 배치 샘플 수 누적\n",
    "        correct += (predicted == labels).sum().item()# 예측 성공 건수 누적\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %f %%' % (\n",
    "    100 * correct / total))  # 최종 정확도 출력"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI Course (Python 3.9)",
   "language": "python",
   "name": "ai_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
